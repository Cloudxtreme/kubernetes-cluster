#cloud-config
ssh_authorized_keys:
 - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCOw/yh7+j3ygZp2aZRdZDWUh0Dkj5N9/USdiLSoS+0CHJta+mtSxxmI/yv1nOk7xnuA6qtjpxdMlWn5obtC9xyS6T++tlTK9gaPwU7a/PObtoZdfQ7znAJDpX0IPI06/OH1tFE9kEutHQPzhCwRaIQ402BHIrUMWzzP7Ige8Oa0HwXH4sHUG5h/V/svzi9T0CKJjF8dTx4iUfKX959hT8wQnKYPULewkNBFv6pNfWIr8EzvIEQcPmmm3tP+dQPKg5QKVi6jPdRla+t5HXfhXu0W3WCDa2s0VGmJjBdMMowr5MLNYI79MKziSV1w1IWL17Z58Lop0zEHqP7Ba0Aooqd
hostname: node-worker2
coreos:
  fleet:
    engine-reconcile-interval: 10
    etcd-request-timeout: 5
    agent-ttl: 120s
    metadata: "region=secondary"
  update:
    reboot-strategy: etcd-lock
  etcd2:
    name: "node-worker2"
    initial-cluster: "node-master=http://192.168.178.130:2380,node-worker0=http://192.168.178.140:2380,node-worker1=http://192.168.178.141:2380,node-worker2=http://192.168.178.142:2380"
    initial-cluster-token: "cluster1"
    initial-cluster-state: "new"
    initial-advertise-peer-urls: "http://192.168.178.142:2380"
    advertise-client-urls: "http://192.168.178.142:2379"
    listen-client-urls: "http://0.0.0.0:2379,http://0.0.0.0:4001"
    listen-peer-urls: "http://0.0.0.0:2380"
  units:
    - name: etc-kubernetes-ssl.mount
      command: start
      content: |
        [Unit]
        Wants=user-configvirtfs.service
        Before=user-configvirtfs.service
        # Only mount config drive block devices automatically in virtual machines
        # or any host that has it explicitly enabled and not explicitly disabled.
        ConditionVirtualization=|vm
        ConditionKernelCommandLine=|coreos.configdrive=1
        ConditionKernelCommandLine=!coreos.configdrive=0
        [Mount]
        What=kubernetes-ssl
        Where=/etc/kubernetes/ssl
        Options=ro,trans=virtio,version=9p2000.L
        Type=9p
    - name: 10-ens3.network
      content: |
        [Match]
        MACAddress=00:16:3e:9d:5d:d8
        [Network]
        Address=192.168.178.142/24
        Gateway=192.168.178.1
        DNS=192.168.178.1
    - name: etcd2.service
      command: start
    - name: fleet.service
      command: start
    - name:  systemd-networkd.service
      command: restart
    - name: flanneld.service
      command: start
      drop-ins:
        - name: 50-network-config.conf
          content: |
            [Service]
            ExecStartPre=/usr/bin/etcdctl set /coreos.com/network/config '{ "Network": "10.101.0.0/16" }'
    - name: docker.service
      command: start
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service
    - name: kubelet.service
      command: start
      content: |
        [Service]
        ExecStart=/usr/bin/kubelet \
          --api_servers=https://192.168.178.130 \
          --register-node=true \
          --allow-privileged=true \
          --config=/etc/kubernetes/manifests \
          --hostname-override=192.168.178.142 \
          --cluster-dns=10.103.0.10 \
          --cluster-domain=cluster.local \
          --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
          --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
          --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target
write_files:
  - path: /etc/environment
    permissions: 0644
    content: |
      COREOS_PUBLIC_IPV4=192.168.178.142
      COREOS_PRIVATE_IPV4=192.168.178.142
  - path: /run/flannel/options.env
    permissions: 0644
    content: |
      FLANNELD_IFACE=192.168.178.142
      FLANNELD_ETCD_ENDPOINTS=http://192.168.178.130:2379,http://192.168.178.140:2379,http://192.168.178.141:2379,http://192.168.178.142:2379
  - path: /etc/kubernetes/worker-kubeconfig.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: local
        cluster:
          certificate-authority: /etc/kubernetes/ssl/ca.pem
      users:
      - name: kubelet
        user:
          client-certificate: /etc/kubernetes/ssl/worker.pem
          client-key: /etc/kubernetes/ssl/worker-key.pem
      contexts:
      - context:
          cluster: local
          user: kubelet
        name: kubelet-context
      current-context: kubelet-context
  - path: /etc/kubernetes/worker-kubeconfig.yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: kube-proxy
      namespace: kube-system
    spec:
      hostNetwork: true
      containers:
      - name: kube-proxy
        image: gcr.io/google_containers/hyperkube:v1.1.2
        command:
        - /hyperkube
        - proxy
        - --master=https://192.168.178.130
        - --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml
        - --proxy-mode=iptables
        securityContext:
          privileged: true
        volumeMounts:
          - mountPath: /etc/ssl/certs
            name: "ssl-certs"
          - mountPath: /etc/kubernetes/worker-kubeconfig.yaml
            name: "kubeconfig"
            readOnly: true
          - mountPath: /etc/kubernetes/ssl
            name: "etc-kube-ssl"
            readOnly: true
      volumes:
        - name: "ssl-certs"
          hostPath:
            path: "/usr/share/ca-certificates"
        - name: "kubeconfig"
          hostPath:
            path: "/etc/kubernetes/worker-kubeconfig.yaml"
        - name: "etc-kube-ssl"
          hostPath:
            path: "/etc/kubernetes/ssl"
